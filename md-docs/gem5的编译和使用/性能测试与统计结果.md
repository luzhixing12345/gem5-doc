
# 性能测试与统计结果

## gem5 的统计模块

gem5 自带了统计模块并提供了使用的头文件, 位于 `include/m5opt.h` 中, 在使用之前我们需要先编译一下对应的静态链接库. 这个库位于 `util/m5` 下, 你可以在 README.md 中找到更多信息

对于 x86 下的编译, 我们直接使用如下命令编译(需要先进入 util/m5 目录下执行)

```bash
cd util/m5
scons build/x86/out/m5
```

> 注意这里的是小写的 x86

编译结束之后将 `build/x86/out/libm5.a` 静态库复制出来, 然后稍微调整一下文件的相对关系

调整后 include/ 下目录结构应如下所示, 其中 m5test 是我们实验的目标文件夹

```bash
├── benchmark
│   ├── m5test
│   │   ├── asm
│   │   │   └── m5ops.h
│   │   ├── libm5.a
│   │   ├── m5ops.h
│   │   ├── m5_statistic.cpp
│   │   ├── Makefile
│   ├── Makefile
└── gem5
    ├── asm
    │   └── generic
    │       └── m5ops.h
    ├── libm5.a
    └── m5ops.h
```

> 注意原 include/gem5 下有两个 m5ops.h, 都并不复杂, 只是将他们移动到另一个文件夹,并修改一下头文件的引用关系即可, 然后将 libm5.a 移动到 m5test 下, m5_statistic.cpp 是我们的测试文件

`m5_statistic.cpp` 测试代码如下所示, 简单的内存访问测试和加法运算, m5_reset_stats 和 m5_dump_stats 则分别用于开始和保存记录,详见 [The m5 Utility(fs mode)](https://www.gem5.org/documentation/general_docs/m5ops/)

```cpp
#include <iostream>
#include <vector>
#include "m5ops.h"

int main() {
    m5_reset_stats(0, 0);
    std::cout << "start program\n";
    std::vector<int> sum(100,0);
    for (int i=0;i<100;i++) {
        sum[i] = i;
    }
    int sum_result = 0;
    for (int i=0;i<100;i++) {
        sum_result += sum[i];
    }
    m5_dump_stats(0, 0);
    std::cout << sum_result << std::endl;
    return 0;
}
```

对应的编译指令如下, 你可以使用 make 来执行

```bash
g++ -L./ m5_statistic.cpp -lm5 -o a
```

这样我们可以得到可执行文件 `a`, 但请注意 **这个程序并不能直接执行**, 因为 libm5.a 需要依赖 gem5 的运行时库, 在本机中是无法执行此文件的, 会出现 `illegal instruction (core dumped)` 的报错

**我们需要将磁盘挂载, 然后将文件夹复制进去编译, 在 fs 中执行才可以得到结果**

- [Understanding gem5 statistics and output](https://www.gem5.org/documentation/learning_gem5/part1/gem5_stats/)
- [gem5 M5ops](https://www.gem5.org/documentation/general_docs/m5ops/)
- [gem5 Stats Package](https://www.gem5.org/documentation/general_docs/statistics/)
- [gem5 Statistics APIs](https://www.gem5.org/documentation/general_docs/statistics/api)
- [Gem5模拟器,详解官网教程的statistics and output(三)](https://blog.csdn.net/qq_46675545/article/details/128278644)
- [Gem5模拟器,如何在linux系统中查看内存、CPU、硬盘、进程、网络等信息(十二)](https://blog.csdn.net/qq_46675545/article/details/129357227)

---

## Stream

Stream测试是内存测试中业界公认的内存带宽性能测试基准工具, 测试行为相对简单可控.该程序对CPU的计算能力要求很小,对CPU内存带宽压力很大.

随着处理器核心数量的增大,而内存带宽并没有随之成线性增长,因此内存带宽对提升多核心的处理能力就越发重要.Stream具有良好的空间局部性,是对TLB友好,Cache友好的一款测试程序,其分为Copy、Scale、Add和Triad四个基本的测试功能.这四个功能描述如下表

|测试功能|基本操作|操作|
|:--:|:--:|:--:|
|Copy|c[i]=a[i]|1R1W|
|Scale|b[i]=scalar*c[i]|1R1W|
|Add|c[i]=a[i]+b[i]|2R1W|
|Triad|a[i]=b[i]+scalar*c[i]|2R1W|

Stream 使用四个基本的的测试功能用于测试 读/写的内存带宽, 其使用方式很简单,源码只有一个 .c 文件, 可以直接通过 wget 下载

```bash
wget http://www.cs.virginia.edu/stream/FTP/Code/stream.c
```

编译

```bash
gcc -O3 -fopenmp -DN=2000000 -DNTIMES=10 stream.c -o stream
```

```bash
-------------------------------------------------------------
STREAM version $Revision: 5.10 $
-------------------------------------------------------------
This system uses 8 bytes per array element.
-------------------------------------------------------------
*****  WARNING: ******
      It appears that you set the preprocessor variable N when compiling this code.
      This version of the code uses the preprocesor variable STREAM_ARRAY_SIZE to control the array size
      Reverting to default value of STREAM_ARRAY_SIZE=10000000
*****  WARNING: ******
Array size = 10000000 (elements), Offset = 0 (elements)
Memory per array = 76.3 MiB (= 0.1 GiB).
Total memory required = 228.9 MiB (= 0.2 GiB).
Each kernel will be executed 10 times.
 The *best* time for each kernel (excluding the first iteration)
 will be used to compute the reported bandwidth.
-------------------------------------------------------------
Number of Threads requested = 16
Number of Threads counted = 16
-------------------------------------------------------------
Your clock granularity/precision appears to be 1 microseconds.
Each test below will take on the order of 24564 microseconds.
   (= 24564 clock ticks)
Increase the size of the arrays if this shows that
you are not getting at least 20 clock ticks per test.
-------------------------------------------------------------
WARNING -- The above is only a rough guideline.
For best results, please be sure you know the
precision of your system timer.
-------------------------------------------------------------
Function    Best Rate MB/s  Avg time     Min time     Max time
Copy:           10877.0     0.034799     0.014710     0.042124
Scale:           7399.2     0.046780     0.021624     0.069402
Add:             8510.4     0.062834     0.028201     0.084992
Triad:           6723.8     0.062384     0.035694     0.086763
-------------------------------------------------------------
Solution Validates: avg error less than 1.000000e-13 on all three arrays
-------------------------------------------------------------
```

本机 CPU 规格如下

```bash
$ lscpu
Architecture:            x86_64
  CPU op-mode(s):        32-bit, 64-bit
  Address sizes:         39 bits physical, 48 bits virtual
  Byte Order:            Little Endian
CPU(s):                  16
  On-line CPU(s) list:   0-15
Vendor ID:               GenuineIntel
  Model name:            11th Gen Intel(R) Core(TM) i7-11800H @ 2.30GHz
    CPU family:          6
    Model:               141
    Thread(s) per core:  2
    Core(s) per socket:  8
    Socket(s):           1
    Stepping:            1
    CPU max MHz:         4600.0000
    CPU min MHz:         800.0000
    BogoMIPS:            4608.00
Virtualization features: 
  Virtualization:        VT-x
Caches (sum of all):     
  L1d:                   384 KiB (8 instances)
  L1i:                   256 KiB (8 instances)
  L2:                    10 MiB (8 instances)
  L3:                    24 MiB (1 instance)

```


 gem5 fs 中

```bash
-------------------------------------------------------------
STREAM version $Revision: 5.10 $
-------------------------------------------------------------
This system uses 8 bytes per array element.
-------------------------------------------------------------
*****  WARNING: ******
      It appears that you set the preprocessor variable N when compiling this code.
      This version of the code uses the preprocesor variable STREAM_ARRAY_SIZE to control the array size
      Reverting to default value of STREAM_ARRAY_SIZE=10000000
*****  WARNING: ******
Array size = 10000000 (elements), Offset = 0 (elements)
Memory per array = 76.3 MiB (= 0.1 GiB).
Total memory required = 228.9 MiB (= 0.2 GiB).
Each kernel will be executed 10 times.
 The *best* time for each kernel (excluding the first iteration)
 will be used to compute the reported bandwidth.
-------------------------------------------------------------
Number of Threads requested = 2
Number of Threads counted = 2
-------------------------------------------------------------
Your clock granularity/precision appears to be 998 microseconds.
Each test below will take on the order of 19996 microseconds.
   (= 20 clock ticks)
Increase the size of the arrays if this shows that
you are not getting at least 20 clock ticks per test.
-------------------------------------------------------------
WARNING -- The above is only a rough guideline.
For best results, please be sure you know the
precision of your system timer.
-------------------------------------------------------------
Function    Best Rate MB/s  Avg time     Min time     Max time
Copy:           11431.2     0.014109     0.013997     0.014998
Scale:           7620.6     0.021330     0.020996     0.021997
Add:            11430.8     0.021330     0.020996     0.021997
Triad:           9232.2     0.026329     0.025996     0.026996
-------------------------------------------------------------
```

- [Stream带宽测试的解释](https://zhuanlan.zhihu.com/p/407489860)

Array size = 10000000 (elements), Offset = 0 (elements)
Memory per array = 76.3 MiB (= 0.1 GiB).
Total memory required = 228.9 MiB (= 0.2 GiB).


```bash
-------------------------------------------------------------
Function    Best Rate MB/s  Avg time     Min time     Max time
Copy:            4557.1     0.035114     0.035110     0.035137
Scale:           3753.1     0.042634     0.042632     0.042636
Add:             5037.0     0.047651     0.047647     0.047655
Triad:           4557.4     0.052665     0.052662     0.052667
-------------------------------------------------------------

```

```bash
cxl
-------------------------------------------------------------
Function    Best Rate MB/s  Avg time     Min time     Max time
Copy:            5671.2     0.028214     0.028213     0.028217
Scale:           3753.1     0.042637     0.042632     0.042660
Add:             5629.7     0.042634     0.042631     0.042636
Triad:           4557.3     0.052666     0.052663     0.052667
-------------------------------------------------------------

```

---

## Redis

```bash
wget https://download.redis.io/redis-stable.tar.gz
tar -xzvf redis-stable.tar.gz
cd redis-stable
make
sudo make install
redis-server
```

```bash
# 本机测试结果
$ redis-benchmark -q -n 100000

PING_INLINE: 227272.73 requests per second, p50=0.111 msec              
PING_MBULK: 222222.22 requests per second, p50=0.111 msec
SET: 227272.73 requests per second, p50=0.111 msec
GET: 227272.73 requests per second, p50=0.111 msec
INCR: 227272.73 requests per second, p50=0.111 msec
LPUSH: 232558.12 requests per second, p50=0.111 msec                   
RPUSH: 227272.73 requests per second, p50=0.111 msec
LPOP: 232558.12 requests per second, p50=0.111 msec
RPOP: 232558.12 requests per second, p50=0.111 msec
SADD: 232558.12 requests per second, p50=0.111 msec
HSET: 238095.23 requests per second, p50=0.111 msec
SPOP: 238095.23 requests per second, p50=0.111 msec                   
ZADD: 238095.23 requests per second, p50=0.111 msec
ZPOPMIN: 238095.23 requests per second, p50=0.111 msec
LPUSH (needed to benchmark LRANGE): 238095.23 requests per second, p50=0.111 msec
LRANGE_100 (first 100 elements): 123456.79 requests per second, p50=0.207 msec
LRANGE_300 (first 300 elements): 48076.92 requests per second, p50=0.511 msec                  
LRANGE_500 (first 500 elements): 31948.88 requests per second, p50=0.775 msec                   
LRANGE_600 (first 600 elements): 27472.53 requests per second, p50=0.903 msec                   
MSET (10 keys): 232558.12 requests per second, p50=0.183 msec
```

---

## 驱动测试

```bash
root@gem5-host:/home/benchmark# ./test1
写入前:0
写入后:65
root@gem5-host:/home/benchmark# ./test2
before mmap
after mmap
原始数据:A
buf = hello,world!
```

```bash
read data = 
write data = A
write data = B
write data = C
read data = A
read data = A
read data = C
read data = A
read data = A
write data = hello,wo�"='V
write data = rld!
write data = 
read data = hello,wo�yx$V
read data = rld!
```

## memkind/vmem分配CXL设备内存的测试

> [【CXL】使用memkind/vmem管理CXL扩展内存](https://blog.csdn.net/qq_45726331/article/details/129824342)

我们这里使用之前下载的 `full-system-image/disks/parsec.img` 磁盘镜像, 创建目录并挂载vfs, 假设此时位于 `~/gem5/full-system-image/disks` 目录下, 即 parsec.img 同级目录

挂载镜像文件到 local_mnt 目录

```bash
mkdir local_mnt
sudo mount -o loop,offset=$((2048*512)) parsec.img local_mnt
sudo mount -o bind /proc local_mnt/proc
sudo mount -o bind /dev local_mnt/dev
sudo mount -o bind /dev/pts local_mnt/dev/pts
sudo mount -o bind /sys local_mnt/sys

cd local_mnt
sudo chroot ./
```

```bash
mkdir /home/lib_source_code
```

[PMDK Version 1.4](https://github.com/pmem/pmdk/releases/tag/1.4)

```bash
wget https://github.com/pmem/pmdk/releases/download/1.4/pmdk-1.4-dpkgs.tar.gz
wget https://github.com/memkind/memkind/archive/refs/tags/v1.14.0.tar.gz
wget http://ftp.jaist.ac.jp/pub/GNU/libtool/libtool-2.4.6.tar.gz
wget https://github.com/numactl/numactl/releases/download/v2.0.16/numactl-2.0.16.tar.gz
```

```bash
cd /home/lib_source_code/
dpkg -i libvmem_1.4-1_amd64.deb
dpkg -l | grep libvmem
```

```bash
root@LZX:/home# dpkg -l | grep libvmem
ii  libvmem                               1.4-1                               amd64        PMDK libvmem library
root@LZX:/home# dpkg -L libvmem
/.
/usr
/usr/lib
/usr/lib/x86_64-linux-gnu
/usr/lib/x86_64-linux-gnu/libvmem.so.1.0.0
/usr/share
/usr/share/doc
/usr/share/doc/libvmem
/usr/share/doc/libvmem/changelog.Debian.gz
/usr/share/doc/libvmem/copyright
/usr/share/lintian
/usr/share/lintian/overrides
/usr/share/lintian/overrides/libvmem
/usr/lib/x86_64-linux-gnu/libvmem.so.1
```

![20230403021208](https://raw.githubusercontent.com/learner-lu/picbed/master/20230403021208.png)

```bash
├── libtool-2.4.6
├── libvmem_1.4-1_amd64.deb
├── memkind-1.14.0
└── numactl-2.0.16
```

```bash
cd numactl-2.0.16
./configure --prefix=/usr/
make -j4
make install
```

```bash
root@LZX:/home/lib_source_code/numactl-2.0.16# ls /usr/lib/ | grep libnuma
libnuma.a
libnuma.la
libnuma.so
libnuma.so.1
libnuma.so.1.0.0
```


```bash
cd libtool-2.4.6
./configure --prefix=/usr/
make
make install
```

> 这里的 make 执行第一遍会出错, 文件夹删了, 第二遍就好了?

```bash
root@LZX:/home/lib_source_code/libtool-2.4.6# ls /usr/lib/ | grep ltdl
libltdl.a
libltdl.la
libltdl.so
libltdl.so.7
libltdl.so.7.3.1
```

```bash
root@LZX:/home/lib_source_code/memkind-1.14.0# ./autogen.sh
libtoolize: putting auxiliary files in '.'.
libtoolize: copying file './ltmain.sh'
libtoolize: putting macros in AC_CONFIG_MACRO_DIRS, 'm4'.
libtoolize: copying file 'm4/libtool.m4'
libtoolize: copying file 'm4/ltoptions.m4'
libtoolize: copying file 'm4/ltsugar.m4'
libtoolize: copying file 'm4/ltversion.m4'
libtoolize: copying file 'm4/lt~obsolete.m4'
```

```bash
./configure --prefix=/usr/
make
make install
```

```bash
root@LZX:/home/lib_source_code/memkind-1.14.0# ls /usr/lib/ | grep kind
libmemkind.a
libmemkind.la
libmemkind.so
libmemkind.so.0
libmemkind.so.0.0.1
```

卸载镜像

```bash
sudo umount local_mnt/proc
sudo umount local_mnt/dev/pts
sudo umount local_mnt/dev
sudo umount local_mnt/sys
sudo umount local_mnt
```

## 参考

